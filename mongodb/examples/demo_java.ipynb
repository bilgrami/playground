{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Flattening Toolkit - Comprehensive Guide (Java Edition)\n",
    "\n",
    "> **A world-class exploration of JSON flattening techniques, patterns, and real-world applications using Java**\n",
    "\n",
    "This notebook is organized into **10 self-contained milestones**, each focusing on specific aspects of JSON flattening. You can work through them sequentially or jump to specific topics of interest.\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "### Foundations\n",
    "- **[Milestone 1: Foundations & Core Concepts](#milestone-1)** - Basic flattening, list policies, separators\n",
    "- **[Milestone 2: Array Handling Strategies](#milestone-2)** - Index vs join, explosion, cartesian products\n",
    "\n",
    "### Advanced Techniques  \n",
    "- **[Milestone 3: Complex Structures](#milestone-3)** - Deep nesting, mixed types, null handling\n",
    "\n",
    "### Real-World Use Cases\n",
    "- **[Milestone 4: E-commerce Data](#milestone-4)** - Orders, products, customers, transactions\n",
    "- **[Milestone 5: API & Event Data](#milestone-5)** - API responses, webhooks, event logs\n",
    "\n",
    "### Data Pipelines\n",
    "- **[Milestone 6: CSV Operations & Pipelines](#milestone-6)** - Read/write, transformations, batch processing\n",
    "\n",
    "### Database Integration\n",
    "- **[Milestone 7: MongoDB Integration](#milestone-7)** - Ingestion, querying, type inference\n",
    "- **[Milestone 8: Snowflake Integration](#milestone-8)** - Schema generation, ingestion, queries\n",
    "\n",
    "### Production Patterns\n",
    "- **[Milestone 9: Advanced Patterns & Best Practices](#milestone-9)** - Performance, memory, error handling\n",
    "- **[Milestone 10: End-to-End Workflows](#milestone-10)** - Complete pipelines, production examples\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- ‚úÖ Flatten complex nested JSON structures efficiently in Java\n",
    "- ‚úÖ Choose appropriate array handling strategies for your use case\n",
    "- ‚úÖ Build data pipelines from JSON to CSV to databases\n",
    "- ‚úÖ Handle edge cases (nulls, empty arrays, mixed types)\n",
    "- ‚úÖ Integrate with MongoDB and Snowflake\n",
    "- ‚úÖ Apply best practices for production systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start\n",
    "\n",
    "Let's set up our environment and import the necessary modules.\n",
    "\n",
    "**Prerequisites:**\n",
    "- IJava kernel installed (https://github.com/SpencerPark/IJava)\n",
    "- Java 11 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ============================================================================\n",
    "// DEPENDENCY MANAGEMENT - Load required libraries\n",
    "// ============================================================================\n",
    "\n",
    "// Using IJava's dependency management\n",
    "%maven com.google.code.gson:gson:2.10.1\n",
    "%maven org.mongodb:mongodb-driver-sync:4.11.1\n",
    "%maven com.opencsv:opencsv:5.9\n",
    "%maven org.apache.commons:commons-lang3:3.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ============================================================================\n",
    "// IMPORTS - All imports at the top for clarity\n",
    "// ============================================================================\n",
    "\n",
    "import com.google.gson.*;\n",
    "import com.opencsv.*;\n",
    "import org.apache.commons.lang3.StringUtils;\n",
    "\n",
    "import java.io.*;\n",
    "import java.nio.file.*;\n",
    "import java.util.*;\n",
    "import java.util.stream.*;\n",
    "import java.time.*;\n",
    "import java.time.format.*;\n",
    "\n",
    "// MongoDB imports (optional - may not be available)\n",
    "import com.mongodb.client.*;\n",
    "import org.bson.Document;\n",
    "\n",
    "System.out.println(\"‚úÖ Imports loaded successfully!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ============================================================================\n",
    "// CORE FLATTENING UTILITIES\n",
    "// ============================================================================\n",
    "\n",
    "/**\n",
    " * Enum for list handling policies\n",
    " */\n",
    "enum ListPolicy {\n",
    "    INDEX,  // Creates indexed keys (tags.0, tags.1)\n",
    "    JOIN    // Joins primitive arrays with commas\n",
    "}\n",
    "\n",
    "/**\n",
    " * JSON Flattening utility class\n",
    " */\n",
    "class JsonFlattener {\n",
    "    private final String separator;\n",
    "    private final ListPolicy listPolicy;\n",
    "    private final Gson gson = new GsonBuilder().setPrettyPrinting().create();\n",
    "    \n",
    "    public JsonFlattener() {\n",
    "        this(\".\", ListPolicy.INDEX);\n",
    "    }\n",
    "    \n",
    "    public JsonFlattener(String separator, ListPolicy listPolicy) {\n",
    "        this.separator = separator;\n",
    "        this.listPolicy = listPolicy;\n",
    "    }\n",
    "    \n",
    "    /**\n",
    "     * Flatten a JSON object into a flat Map\n",
    "     */\n",
    "    public Map<String, Object> flatten(JsonObject json) {\n",
    "        Map<String, Object> result = new LinkedHashMap<>();\n",
    "        flattenElement(\"\", json, result);\n",
    "        return result;\n",
    "    }\n",
    "    \n",
    "    /**\n",
    "     * Flatten a JSON string into a flat Map\n",
    "     */\n",
    "    public Map<String, Object> flatten(String jsonString) {\n",
    "        JsonObject json = JsonParser.parseString(jsonString).getAsJsonObject();\n",
    "        return flatten(json);\n",
    "    }\n",
    "    \n",
    "    private void flattenElement(String prefix, JsonElement element, Map<String, Object> result) {\n",
    "        if (element.isJsonNull()) {\n",
    "            result.put(prefix, null);\n",
    "        } else if (element.isJsonPrimitive()) {\n",
    "            JsonPrimitive prim = element.getAsJsonPrimitive();\n",
    "            if (prim.isBoolean()) {\n",
    "                result.put(prefix, prim.getAsBoolean());\n",
    "            } else if (prim.isNumber()) {\n",
    "                Number num = prim.getAsNumber();\n",
    "                if (num.doubleValue() == num.longValue()) {\n",
    "                    result.put(prefix, num.longValue());\n",
    "                } else {\n",
    "                    result.put(prefix, num.doubleValue());\n",
    "                }\n",
    "            } else {\n",
    "                result.put(prefix, prim.getAsString());\n",
    "            }\n",
    "        } else if (element.isJsonObject()) {\n",
    "            JsonObject obj = element.getAsJsonObject();\n",
    "            for (Map.Entry<String, JsonElement> entry : obj.entrySet()) {\n",
    "                String newKey = prefix.isEmpty() ? entry.getKey() : prefix + separator + entry.getKey();\n",
    "                flattenElement(newKey, entry.getValue(), result);\n",
    "            }\n",
    "        } else if (element.isJsonArray()) {\n",
    "            JsonArray arr = element.getAsJsonArray();\n",
    "            if (listPolicy == ListPolicy.JOIN && isAllPrimitives(arr)) {\n",
    "                String joined = StreamSupport.stream(arr.spliterator(), false)\n",
    "                    .map(e -> e.isJsonNull() ? \"\" : e.getAsString())\n",
    "                    .collect(Collectors.joining(\",\"));\n",
    "                result.put(prefix, joined);\n",
    "            } else {\n",
    "                for (int i = 0; i < arr.size(); i++) {\n",
    "                    String newKey = prefix + separator + i;\n",
    "                    flattenElement(newKey, arr.get(i), result);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    private boolean isAllPrimitives(JsonArray arr) {\n",
    "        return StreamSupport.stream(arr.spliterator(), false)\n",
    "            .allMatch(e -> e.isJsonPrimitive() || e.isJsonNull());\n",
    "    }\n",
    "    \n",
    "    /**\n",
    "     * Explode arrays into multiple records (cartesian product)\n",
    "     */\n",
    "    public List<Map<String, Object>> flattenRecords(JsonObject json, List<String> explodePaths) {\n",
    "        List<Map<String, Object>> results = new ArrayList<>();\n",
    "        results.add(new LinkedHashMap<>());\n",
    "        \n",
    "        flattenRecordsHelper(\"\", json, results, new HashSet<>(explodePaths));\n",
    "        return results;\n",
    "    }\n",
    "    \n",
    "    private void flattenRecordsHelper(String prefix, JsonElement element, \n",
    "                                       List<Map<String, Object>> results, Set<String> explodePaths) {\n",
    "        if (element.isJsonNull()) {\n",
    "            for (Map<String, Object> record : results) {\n",
    "                record.put(prefix, null);\n",
    "            }\n",
    "        } else if (element.isJsonPrimitive()) {\n",
    "            JsonPrimitive prim = element.getAsJsonPrimitive();\n",
    "            Object value;\n",
    "            if (prim.isBoolean()) {\n",
    "                value = prim.getAsBoolean();\n",
    "            } else if (prim.isNumber()) {\n",
    "                Number num = prim.getAsNumber();\n",
    "                value = (num.doubleValue() == num.longValue()) ? num.longValue() : num.doubleValue();\n",
    "            } else {\n",
    "                value = prim.getAsString();\n",
    "            }\n",
    "            for (Map<String, Object> record : results) {\n",
    "                record.put(prefix, value);\n",
    "            }\n",
    "        } else if (element.isJsonObject()) {\n",
    "            JsonObject obj = element.getAsJsonObject();\n",
    "            for (Map.Entry<String, JsonElement> entry : obj.entrySet()) {\n",
    "                String newKey = prefix.isEmpty() ? entry.getKey() : prefix + separator + entry.getKey();\n",
    "                flattenRecordsHelper(newKey, entry.getValue(), results, explodePaths);\n",
    "            }\n",
    "        } else if (element.isJsonArray()) {\n",
    "            JsonArray arr = element.getAsJsonArray();\n",
    "            if (explodePaths.contains(prefix)) {\n",
    "                // Explode: multiply records\n",
    "                List<Map<String, Object>> newResults = new ArrayList<>();\n",
    "                for (int i = 0; i < arr.size(); i++) {\n",
    "                    for (Map<String, Object> record : results) {\n",
    "                        Map<String, Object> newRecord = new LinkedHashMap<>(record);\n",
    "                        List<Map<String, Object>> singleRecordList = new ArrayList<>();\n",
    "                        singleRecordList.add(newRecord);\n",
    "                        flattenRecordsHelper(prefix, arr.get(i), singleRecordList, explodePaths);\n",
    "                        newResults.addAll(singleRecordList);\n",
    "                    }\n",
    "                }\n",
    "                results.clear();\n",
    "                results.addAll(newResults);\n",
    "            } else if (listPolicy == ListPolicy.JOIN && isAllPrimitives(arr)) {\n",
    "                String joined = StreamSupport.stream(arr.spliterator(), false)\n",
    "                    .map(e -> e.isJsonNull() ? \"\" : e.getAsString())\n",
    "                    .collect(Collectors.joining(\",\"));\n",
    "                for (Map<String, Object> record : results) {\n",
    "                    record.put(prefix, joined);\n",
    "                }\n",
    "            } else {\n",
    "                for (int i = 0; i < arr.size(); i++) {\n",
    "                    String newKey = prefix + separator + i;\n",
    "                    flattenRecordsHelper(newKey, arr.get(i), results, explodePaths);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public String toJson(Object obj) {\n",
    "        return gson.toJson(obj);\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"‚úÖ JsonFlattener class defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ============================================================================\n",
    "// HELPER UTILITIES\n",
    "// ============================================================================\n",
    "\n",
    "class Utils {\n",
    "    private static final Gson gson = new GsonBuilder().setPrettyPrinting().create();\n",
    "    \n",
    "    public static void printSection(String title) {\n",
    "        printSection(title, '=');\n",
    "    }\n",
    "    \n",
    "    public static void printSection(String title, char ch) {\n",
    "        String line = String.valueOf(ch).repeat(60);\n",
    "        System.out.println(\"\\n\" + line);\n",
    "        System.out.println(\"  \" + title);\n",
    "        System.out.println(line + \"\\n\");\n",
    "    }\n",
    "    \n",
    "    public static void compareBeforeAfter(String before, Map<String, Object> after, String title) {\n",
    "        printSection(title);\n",
    "        System.out.println(\"BEFORE (Original JSON):\");\n",
    "        System.out.println(formatJson(before));\n",
    "        System.out.println(\"\\nAFTER (Flattened):\");\n",
    "        System.out.println(gson.toJson(after));\n",
    "        System.out.println(\"\\nüìä Flattened to \" + after.size() + \" fields\");\n",
    "    }\n",
    "    \n",
    "    public static String formatJson(String json) {\n",
    "        JsonElement el = JsonParser.parseString(json);\n",
    "        return gson.toJson(el);\n",
    "    }\n",
    "    \n",
    "    public static String readFile(String path) throws IOException {\n",
    "        return Files.readString(Path.of(path));\n",
    "    }\n",
    "    \n",
    "    public static void writeFile(String path, String content) throws IOException {\n",
    "        Files.writeString(Path.of(path), content);\n",
    "    }\n",
    "    \n",
    "    public static long measureTime(Runnable task) {\n",
    "        long start = System.nanoTime();\n",
    "        task.run();\n",
    "        long elapsed = System.nanoTime() - start;\n",
    "        System.out.println(\"‚è±Ô∏è  Execution time: \" + (elapsed / 1_000_000.0) + \" ms\");\n",
    "        return elapsed;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Create output directory\n",
    "Path outputDir = Path.of(\"notebook_output\");\n",
    "Files.createDirectories(outputDir);\n",
    "\n",
    "System.out.println(\"‚úÖ Environment setup complete!\");\n",
    "System.out.println(\"üìÅ Output directory: \" + outputDir.toAbsolutePath());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-1\"></a>\n",
    "\n",
    "# Milestone 1: Foundations & Core Concepts\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the fundamental concept of JSON flattening\n",
    "- Learn how nested structures are converted to flat dictionaries\n",
    "- Explore different list handling policies\n",
    "- Master custom separator usage\n",
    "\n",
    "## Why Flatten JSON?\n",
    "\n",
    "Data engineers and data scientists frequently encounter challenges:\n",
    "- **Tabular formats** (CSV, databases) require flat structures\n",
    "- **Analytics tools** work better with normalized data\n",
    "- **Schema inference** is easier with flat structures\n",
    "- **Database ingestion** requires consistent column structures\n",
    "\n",
    "Let's start with the basics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understanding Nested Structures\n",
    "\n",
    "**What is nesting?**  \n",
    "Nesting occurs when JSON objects contain other objects or arrays inside them. Think of it like Russian dolls - objects within objects.\n",
    "\n",
    "**Why is this a problem?**  \n",
    "- Databases expect flat tables with columns\n",
    "- CSV files are inherently flat (rows and columns)\n",
    "- Analytics tools work better with normalized data\n",
    "- Schema inference becomes complex with nested structures\n",
    "\n",
    "**How does flattening work?**  \n",
    "The `JsonFlattener.flatten()` method recursively traverses nested structures and creates dot-delimited keys. For example:\n",
    "- `user.profile.name` represents the `name` field inside `profile` inside `user`\n",
    "- The dot (`.`) is the default separator, but you can customize it\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Example 1: Simple nested structure\n",
    "String json1 = \"\"\"\n",
    "    {\n",
    "        \"user\": {\n",
    "            \"id\": 42,\n",
    "            \"profile\": {\n",
    "                \"name\": \"Alice\",\n",
    "                \"active\": true\n",
    "            }\n",
    "        },\n",
    "        \"score\": 9.5\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "Map<String, Object> flattened1 = flattener.flatten(json1);\n",
    "\n",
    "Utils.compareBeforeAfter(json1, flattened1, \"Example 1: Simple Nested Structure\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Custom Separators\n",
    "\n",
    "**Why use custom separators?**  \n",
    "Sometimes the default dot (`.`) separator can conflict with your data:\n",
    "- Field names might contain dots\n",
    "- You might prefer underscores (`_`) or double underscores (`__`)\n",
    "- Some systems have naming conventions\n",
    "\n",
    "**Example use cases:**\n",
    "- MongoDB uses dots for nested queries, so you might want `_` instead\n",
    "- Some databases prefer `__` for clarity\n",
    "- Your organization might have specific naming standards\n",
    "\n",
    "Let's explore different separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Example 2: Custom separators\n",
    "String json2 = \"\"\"\n",
    "    {\n",
    "        \"user\": {\n",
    "            \"name\": \"Bob\",\n",
    "            \"address\": {\n",
    "                \"city\": \"NYC\",\n",
    "                \"zip\": \"10001\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "Utils.printSection(\"Custom Separators Comparison\");\n",
    "\n",
    "// Default dot separator\n",
    "JsonFlattener dotFlattener = new JsonFlattener(\".\", ListPolicy.INDEX);\n",
    "System.out.println(\"With dot (.) separator:\");\n",
    "System.out.println(dotFlattener.toJson(dotFlattener.flatten(json2)));\n",
    "\n",
    "// Underscore separator\n",
    "JsonFlattener underscoreFlattener = new JsonFlattener(\"_\", ListPolicy.INDEX);\n",
    "System.out.println(\"\\nWith underscore (_) separator:\");\n",
    "System.out.println(underscoreFlattener.toJson(underscoreFlattener.flatten(json2)));\n",
    "\n",
    "// Double underscore separator\n",
    "JsonFlattener doubleUnderscoreFlattener = new JsonFlattener(\"__\", ListPolicy.INDEX);\n",
    "System.out.println(\"\\nWith double underscore (__) separator:\");\n",
    "System.out.println(doubleUnderscoreFlattener.toJson(doubleUnderscoreFlattener.flatten(json2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Handling\n",
    "\n",
    "Arrays can be handled in two ways:\n",
    "- **Index policy**: Creates indexed keys (e.g., `tags.0`, `tags.1`)\n",
    "- **Join policy**: Joins primitive arrays with commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Example: Array explosion - creating multiple records\n",
    "String json5 = \"\"\"\n",
    "    {\n",
    "        \"order_id\": 1001,\n",
    "        \"customer\": \"Alice\",\n",
    "        \"items\": [\n",
    "            {\"sku\": \"A1\", \"qty\": 2, \"price\": 10.50},\n",
    "            {\"sku\": \"B2\", \"qty\": 1, \"price\": 5.25},\n",
    "            {\"sku\": \"C3\", \"qty\": 3, \"price\": 8.00}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject jsonObj = JsonParser.parseString(json5).getAsJsonObject();\n",
    "List<Map<String, Object>> records = flattener.flattenRecords(jsonObj, List.of(\"items\"));\n",
    "\n",
    "System.out.println(\"Created \" + records.size() + \" records from array explosion:\");\n",
    "for (int i = 0; i < records.size(); i++) {\n",
    "    System.out.println(\"\\nRecord \" + (i + 1) + \":\");\n",
    "    System.out.println(flattener.toJson(records.get(i)));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-2\"></a>\n",
    "\n",
    "# Milestone 2: Array Handling Strategies\n",
    "\n",
    "## Learning Objectives\n",
    "- Compare index vs join list policies\n",
    "- Understand array explosion into multiple records\n",
    "- Create cartesian products across multiple array paths\n",
    "\n",
    "Arrays are where flattening decisions have the biggest downstream impact. We'll compare policies and then explode arrays into multiple records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Index vs Join list policies\");\n",
    "\n",
    "String arrayData = \"\"\"\n",
    "    {\n",
    "        \"tags\": [\"alpha\", \"beta\", \"gamma\"],\n",
    "        \"metrics\": {\"scores\": [10, 20, null]},\n",
    "        \"meta\": {\"ids\": [1, 2, 3]}\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener indexFlattener = new JsonFlattener(\".\", ListPolicy.INDEX);\n",
    "JsonFlattener joinFlattener = new JsonFlattener(\".\", ListPolicy.JOIN);\n",
    "\n",
    "System.out.println(\"Index policy output:\");\n",
    "System.out.println(indexFlattener.toJson(indexFlattener.flatten(arrayData)));\n",
    "\n",
    "System.out.println(\"\\nJoin policy output:\");\n",
    "System.out.println(joinFlattener.toJson(joinFlattener.flatten(arrayData)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Array explosion and cartesian products\");\n",
    "\n",
    "String multiPathData = \"\"\"\n",
    "    {\n",
    "        \"order_id\": 1,\n",
    "        \"items\": [\n",
    "            {\"sku\": \"A\"},\n",
    "            {\"sku\": \"B\"}\n",
    "        ],\n",
    "        \"discounts\": [\n",
    "            {\"code\": \"SAVE10\"},\n",
    "            {\"code\": \"BONUS\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject jsonObj = JsonParser.parseString(multiPathData).getAsJsonObject();\n",
    "List<Map<String, Object>> records = flattener.flattenRecords(jsonObj, List.of(\"items\", \"discounts\"));\n",
    "\n",
    "System.out.println(\"Exploded to \" + records.size() + \" records (cartesian product):\");\n",
    "for (Map<String, Object> record : records) {\n",
    "    System.out.println(flattener.toJson(record));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-3\"></a>\n",
    "\n",
    "# Milestone 3: Complex Structures\n",
    "\n",
    "## Learning Objectives\n",
    "- Handle deep nesting and mixed types\n",
    "- Process nulls, empty arrays, and optional fields\n",
    "- Work with nested arrays inside arrays\n",
    "\n",
    "These scenarios mirror real data engineering edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deep nesting example\n",
    "Utils.printSection(\"Deep Nesting\");\n",
    "\n",
    "String deepNestingJson = \"\"\"\n",
    "    {\n",
    "        \"level1\": {\n",
    "            \"level2\": {\n",
    "                \"level3\": {\n",
    "                    \"level4\": {\n",
    "                        \"value\": \"deeply nested\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "Map<String, Object> deepFlattened = flattener.flatten(deepNestingJson);\n",
    "Utils.compareBeforeAfter(deepNestingJson, deepFlattened, \"Deep Nesting\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Mixed types example\n",
    "Utils.printSection(\"Mixed Types\");\n",
    "\n",
    "String mixedTypesJson = \"\"\"\n",
    "    {\n",
    "        \"string_field\": \"hello\",\n",
    "        \"int_field\": 42,\n",
    "        \"float_field\": 3.14,\n",
    "        \"bool_field\": true,\n",
    "        \"null_field\": null,\n",
    "        \"array_field\": [1, \"two\", 3.0, true, null]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "Map<String, Object> mixedFlattened = flattener.flatten(mixedTypesJson);\n",
    "Utils.compareBeforeAfter(mixedTypesJson, mixedFlattened, \"Mixed Types\");\n",
    "\n",
    "// Show types\n",
    "System.out.println(\"\\nField types:\");\n",
    "for (Map.Entry<String, Object> entry : mixedFlattened.entrySet()) {\n",
    "    String type = entry.getValue() == null ? \"null\" : entry.getValue().getClass().getSimpleName();\n",
    "    System.out.println(\"  \" + entry.getKey() + \": \" + type);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Empty and null handling\n",
    "Utils.printSection(\"Empty and Null Handling\");\n",
    "\n",
    "String nullHandlingJson = \"\"\"\n",
    "    {\n",
    "        \"present\": \"value\",\n",
    "        \"empty_string\": \"\",\n",
    "        \"null_value\": null,\n",
    "        \"empty_array\": [],\n",
    "        \"empty_object\": {},\n",
    "        \"nested\": {\n",
    "            \"null_inside\": null,\n",
    "            \"value_inside\": 123\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "Map<String, Object> nullFlattened = flattener.flatten(nullHandlingJson);\n",
    "Utils.compareBeforeAfter(nullHandlingJson, nullFlattened, \"Empty and Null Handling\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-4\"></a>\n",
    "\n",
    "# Milestone 4: E-commerce Data\n",
    "\n",
    "## Learning Objectives\n",
    "- Flatten orders with line items\n",
    "- Create cartesian combinations across items and discounts\n",
    "- Preserve customer metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"E-commerce Order Processing\");\n",
    "\n",
    "String orderJson = \"\"\"\n",
    "    {\n",
    "        \"order_id\": \"ORD-2024-001\",\n",
    "        \"customer\": {\n",
    "            \"id\": \"cust_001\",\n",
    "            \"name\": \"Ada Lovelace\",\n",
    "            \"segment\": \"enterprise\"\n",
    "        },\n",
    "        \"items\": [\n",
    "            {\"sku\": \"LAPTOP-001\", \"name\": \"MacBook Pro\", \"qty\": 1, \"price\": 2499.00},\n",
    "            {\"sku\": \"MOUSE-002\", \"name\": \"Magic Mouse\", \"qty\": 2, \"price\": 99.00}\n",
    "        ],\n",
    "        \"discounts\": [\n",
    "            {\"code\": \"ENTERPRISE20\", \"percent\": 20},\n",
    "            {\"code\": \"FREESHIP\", \"percent\": 0}\n",
    "        ],\n",
    "        \"shipping\": {\n",
    "            \"address\": {\n",
    "                \"street\": \"123 Tech Lane\",\n",
    "                \"city\": \"San Francisco\",\n",
    "                \"state\": \"CA\",\n",
    "                \"zip\": \"94105\"\n",
    "            },\n",
    "            \"method\": \"express\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject orderObj = JsonParser.parseString(orderJson).getAsJsonObject();\n",
    "List<Map<String, Object>> orderRecords = flattener.flattenRecords(orderObj, List.of(\"items\", \"discounts\"));\n",
    "\n",
    "System.out.println(\"Created \" + orderRecords.size() + \" order records (items x discounts):\");\n",
    "for (int i = 0; i < orderRecords.size(); i++) {\n",
    "    System.out.println(\"\\nRecord \" + (i + 1) + \":\");\n",
    "    Map<String, Object> record = orderRecords.get(i);\n",
    "    // Show key fields only\n",
    "    System.out.println(\"  order_id: \" + record.get(\"order_id\"));\n",
    "    System.out.println(\"  items.sku: \" + record.get(\"items.sku\"));\n",
    "    System.out.println(\"  items.name: \" + record.get(\"items.name\"));\n",
    "    System.out.println(\"  discounts.code: \" + record.get(\"discounts.code\"));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-5\"></a>\n",
    "\n",
    "# Milestone 5: API & Event Data\n",
    "\n",
    "## Learning Objectives\n",
    "- Flatten nested API responses\n",
    "- Handle event log arrays\n",
    "- Normalize timestamps for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "String apiResponse = \"\"\"\n",
    "    {\n",
    "        \"request_id\": \"req_123\",\n",
    "        \"status\": \"ok\",\n",
    "        \"data\": {\n",
    "            \"user\": {\"id\": 7, \"name\": \"Grace\"},\n",
    "            \"roles\": [\"admin\", \"editor\"],\n",
    "            \"metadata\": {\"source\": \"web\", \"region\": \"us-east-1\"}\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener joinFlattener = new JsonFlattener(\".\", ListPolicy.JOIN);\n",
    "Map<String, Object> flattenedApi = joinFlattener.flatten(apiResponse);\n",
    "Utils.compareBeforeAfter(apiResponse, flattenedApi, \"API Response Flattening\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Event log normalization\");\n",
    "\n",
    "String eventPayload = \"\"\"\n",
    "    {\n",
    "        \"service\": \"billing\",\n",
    "        \"events\": [\n",
    "            {\"type\": \"created\", \"timestamp\": \"2024-01-15T10:30:00Z\", \"amount\": 45.5},\n",
    "            {\"type\": \"captured\", \"timestamp\": \"2024-01-15T10:31:05Z\", \"amount\": 45.5}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject eventObj = JsonParser.parseString(eventPayload).getAsJsonObject();\n",
    "List<Map<String, Object>> eventRecords = flattener.flattenRecords(eventObj, List.of(\"events\"));\n",
    "\n",
    "System.out.println(\"Created \" + eventRecords.size() + \" event records:\");\n",
    "for (Map<String, Object> record : eventRecords) {\n",
    "    System.out.println(flattener.toJson(record));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-6\"></a>\n",
    "\n",
    "# Milestone 6: CSV Operations & Pipelines\n",
    "\n",
    "## Learning Objectives\n",
    "- Write flattened records to CSV\n",
    "- Read CSV back into Java\n",
    "- Build repeatable batch pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// CSV Writer utility\n",
    "class CsvUtils {\n",
    "    \n",
    "    public static void writeCsv(List<Map<String, Object>> records, Path path) throws IOException {\n",
    "        if (records.isEmpty()) {\n",
    "            throw new IllegalArgumentException(\"No records to write\");\n",
    "        }\n",
    "        \n",
    "        // Collect all unique headers\n",
    "        Set<String> headerSet = new LinkedHashSet<>();\n",
    "        for (Map<String, Object> record : records) {\n",
    "            headerSet.addAll(record.keySet());\n",
    "        }\n",
    "        List<String> headers = new ArrayList<>(headerSet);\n",
    "        \n",
    "        try (CSVWriter writer = new CSVWriter(new FileWriter(path.toFile()))) {\n",
    "            // Write header\n",
    "            writer.writeNext(headers.toArray(new String[0]));\n",
    "            \n",
    "            // Write data rows\n",
    "            for (Map<String, Object> record : records) {\n",
    "                String[] row = headers.stream()\n",
    "                    .map(h -> {\n",
    "                        Object val = record.get(h);\n",
    "                        return val == null ? \"\" : String.valueOf(val);\n",
    "                    })\n",
    "                    .toArray(String[]::new);\n",
    "                writer.writeNext(row);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public static List<Map<String, String>> readCsv(Path path) throws IOException {\n",
    "        List<Map<String, String>> records = new ArrayList<>();\n",
    "        \n",
    "        try (CSVReader reader = new CSVReader(new FileReader(path.toFile()))) {\n",
    "            String[] headers = reader.readNext();\n",
    "            if (headers == null) return records;\n",
    "            \n",
    "            String[] row;\n",
    "            while ((row = reader.readNext()) != null) {\n",
    "                Map<String, String> record = new LinkedHashMap<>();\n",
    "                for (int i = 0; i < headers.length && i < row.length; i++) {\n",
    "                    record.put(headers[i], row[i]);\n",
    "                }\n",
    "                records.add(record);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return records;\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"‚úÖ CsvUtils class defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Write flattened records to CSV\n",
    "Utils.printSection(\"CSV Pipeline\");\n",
    "\n",
    "String sampleOrder = \"\"\"\n",
    "    {\n",
    "        \"order_id\": 1001,\n",
    "        \"customer\": {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "        \"items\": [\n",
    "            {\"sku\": \"A1\", \"qty\": 2},\n",
    "            {\"sku\": \"B2\", \"qty\": 1}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject orderObj = JsonParser.parseString(sampleOrder).getAsJsonObject();\n",
    "List<Map<String, Object>> records = flattener.flattenRecords(orderObj, List.of(\"items\"));\n",
    "\n",
    "Path csvPath = outputDir.resolve(\"orders.csv\");\n",
    "CsvUtils.writeCsv(records, csvPath);\n",
    "\n",
    "System.out.println(\"‚úì Written \" + records.size() + \" records to \" + csvPath);\n",
    "System.out.println(\"\\nCSV content:\");\n",
    "System.out.println(Files.readString(csvPath));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read CSV back (round-trip)\n",
    "System.out.println(\"\\nRound-trip read:\");\n",
    "List<Map<String, String>> roundTrip = CsvUtils.readCsv(csvPath);\n",
    "for (Map<String, String> row : roundTrip) {\n",
    "    System.out.println(row);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-7\"></a>\n",
    "\n",
    "# Milestone 7: MongoDB Integration\n",
    "\n",
    "## Learning Objectives\n",
    "- Ingest flattened records into MongoDB\n",
    "- Query collections for analytics\n",
    "- Understand type inference behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// MongoDB integration utilities\n",
    "class MongoUtils {\n",
    "    \n",
    "    public static int ingestToMongo(List<Map<String, Object>> records, \n",
    "                                    String uri, String database, String collection) {\n",
    "        try (MongoClient client = MongoClients.create(uri)) {\n",
    "            MongoDatabase db = client.getDatabase(database);\n",
    "            MongoCollection<Document> coll = db.getCollection(collection);\n",
    "            \n",
    "            List<Document> documents = records.stream()\n",
    "                .map(Document::new)\n",
    "                .collect(Collectors.toList());\n",
    "            \n",
    "            coll.insertMany(documents);\n",
    "            return documents.size();\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public static List<Document> queryMongo(String uri, String database, \n",
    "                                            String collection, int limit) {\n",
    "        try (MongoClient client = MongoClients.create(uri)) {\n",
    "            MongoDatabase db = client.getDatabase(database);\n",
    "            MongoCollection<Document> coll = db.getCollection(collection);\n",
    "            \n",
    "            return coll.find().limit(limit).into(new ArrayList<>());\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"‚úÖ MongoUtils class defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"MongoDB Integration\");\n",
    "\n",
    "String mongoUri = System.getenv().getOrDefault(\"MONGO_URI\", \"mongodb://localhost:27017\");\n",
    "String databaseName = System.getenv().getOrDefault(\"MONGO_DB\", \"json_flatten_demo\");\n",
    "String collectionName = System.getenv().getOrDefault(\"MONGO_COLLECTION\", \"orders_java\");\n",
    "\n",
    "try {\n",
    "    // Prepare sample records\n",
    "    String sampleData = \"\"\"\n",
    "        {\n",
    "            \"order_id\": 2001,\n",
    "            \"customer\": \"Bob\",\n",
    "            \"items\": [\n",
    "                {\"sku\": \"X1\", \"qty\": 3},\n",
    "                {\"sku\": \"Y2\", \"qty\": 1}\n",
    "            ]\n",
    "        }\n",
    "        \"\"\";\n",
    "    \n",
    "    JsonFlattener flattener = new JsonFlattener();\n",
    "    JsonObject jsonObj = JsonParser.parseString(sampleData).getAsJsonObject();\n",
    "    List<Map<String, Object>> records = flattener.flattenRecords(jsonObj, List.of(\"items\"));\n",
    "    \n",
    "    int inserted = MongoUtils.ingestToMongo(records, mongoUri, databaseName, collectionName);\n",
    "    System.out.println(\"Inserted \" + inserted + \" documents into \" + databaseName + \".\" + collectionName);\n",
    "    \n",
    "    // Query back\n",
    "    List<Document> docs = MongoUtils.queryMongo(mongoUri, databaseName, collectionName, 3);\n",
    "    System.out.println(\"\\nSample documents:\");\n",
    "    for (Document doc : docs) {\n",
    "        System.out.println(doc.toJson());\n",
    "    }\n",
    "} catch (Exception e) {\n",
    "    System.out.println(\"MongoDB integration skipped: \" + e.getMessage());\n",
    "    System.out.println(\"(Make sure MongoDB is running on \" + mongoUri + \")\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-8\"></a>\n",
    "\n",
    "# Milestone 8: Snowflake Integration\n",
    "\n",
    "## Learning Objectives\n",
    "- Generate Snowflake table schemas\n",
    "- Understand type mapping from Java to Snowflake\n",
    "- Prepare data for Snowflake ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Snowflake schema generation utility\n",
    "class SnowflakeUtils {\n",
    "    \n",
    "    public static String inferSnowflakeType(Object value) {\n",
    "        if (value == null) return \"VARCHAR\";\n",
    "        if (value instanceof Boolean) return \"BOOLEAN\";\n",
    "        if (value instanceof Long || value instanceof Integer) return \"INTEGER\";\n",
    "        if (value instanceof Double || value instanceof Float) return \"FLOAT\";\n",
    "        return \"VARCHAR\";\n",
    "    }\n",
    "    \n",
    "    public static String generateCreateTable(List<Map<String, Object>> records, \n",
    "                                              String tableName, String schema) {\n",
    "        if (records.isEmpty()) {\n",
    "            throw new IllegalArgumentException(\"No records to infer schema\");\n",
    "        }\n",
    "        \n",
    "        // Collect all columns and infer types from first non-null value\n",
    "        Map<String, String> columnTypes = new LinkedHashMap<>();\n",
    "        \n",
    "        for (Map<String, Object> record : records) {\n",
    "            for (Map.Entry<String, Object> entry : record.entrySet()) {\n",
    "                String col = entry.getKey();\n",
    "                if (!columnTypes.containsKey(col) || columnTypes.get(col).equals(\"VARCHAR\")) {\n",
    "                    if (entry.getValue() != null) {\n",
    "                        columnTypes.put(col, inferSnowflakeType(entry.getValue()));\n",
    "                    } else if (!columnTypes.containsKey(col)) {\n",
    "                        columnTypes.put(col, \"VARCHAR\");\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        StringBuilder sb = new StringBuilder();\n",
    "        sb.append(\"CREATE TABLE IF NOT EXISTS \").append(schema).append(\".\").append(tableName).append(\" (\\n\");\n",
    "        \n",
    "        List<String> columnDefs = new ArrayList<>();\n",
    "        for (Map.Entry<String, String> entry : columnTypes.entrySet()) {\n",
    "            // Sanitize column name (replace dots with underscores)\n",
    "            String colName = entry.getKey().replace(\".\", \"_\").toUpperCase();\n",
    "            columnDefs.add(\"    \" + colName + \" \" + entry.getValue());\n",
    "        }\n",
    "        \n",
    "        sb.append(String.join(\",\\n\", columnDefs));\n",
    "        sb.append(\"\\n);\");\n",
    "        \n",
    "        return sb.toString();\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"‚úÖ SnowflakeUtils class defined!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Snowflake Schema Generation\");\n",
    "\n",
    "// Use our existing order records\n",
    "String orderData = \"\"\"\n",
    "    {\n",
    "        \"order_id\": 3001,\n",
    "        \"total\": 156.75,\n",
    "        \"paid\": true,\n",
    "        \"customer\": {\"name\": \"Charlie\", \"tier\": \"gold\"},\n",
    "        \"items\": [\n",
    "            {\"sku\": \"P1\", \"qty\": 2, \"price\": 50.00},\n",
    "            {\"sku\": \"P2\", \"qty\": 1, \"price\": 56.75}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject orderObj = JsonParser.parseString(orderData).getAsJsonObject();\n",
    "List<Map<String, Object>> records = flattener.flattenRecords(orderObj, List.of(\"items\"));\n",
    "\n",
    "String schemaSql = SnowflakeUtils.generateCreateTable(records, \"ORDERS_FLAT\", \"PUBLIC\");\n",
    "System.out.println(schemaSql);\n",
    "\n",
    "System.out.println(\"\\nNote: Actual Snowflake ingestion requires JDBC driver and credentials.\");\n",
    "System.out.println(\"Set SNOWFLAKE_* environment variables and use snowflake-jdbc driver.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-9\"></a>\n",
    "\n",
    "# Milestone 9: Advanced Patterns & Best Practices\n",
    "\n",
    "## Learning Objectives\n",
    "- Measure performance for large workloads\n",
    "- Avoid unintended cartesian explosions\n",
    "- Understand memory considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Performance Measurement\");\n",
    "\n",
    "// Generate a large cartesian product scenario\n",
    "String largeCartesian = \"\"\"\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"items\": [\n",
    "            {\"sku\": \"A\"}, {\"sku\": \"B\"}, {\"sku\": \"C\"}, {\"sku\": \"D\"}, {\"sku\": \"E\"},\n",
    "            {\"sku\": \"F\"}, {\"sku\": \"G\"}, {\"sku\": \"H\"}, {\"sku\": \"I\"}, {\"sku\": \"J\"}\n",
    "        ],\n",
    "        \"promos\": [\n",
    "            {\"code\": \"P1\"}, {\"code\": \"P2\"}, {\"code\": \"P3\"}, {\"code\": \"P4\"}, {\"code\": \"P5\"}\n",
    "        ],\n",
    "        \"regions\": [\n",
    "            {\"name\": \"R1\"}, {\"name\": \"R2\"}, {\"name\": \"R3\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject largeObj = JsonParser.parseString(largeCartesian).getAsJsonObject();\n",
    "\n",
    "// Measure time\n",
    "long start = System.nanoTime();\n",
    "List<Map<String, Object>> largeRecords = flattener.flattenRecords(\n",
    "    largeObj, List.of(\"items\", \"promos\", \"regions\")\n",
    ");\n",
    "long elapsed = System.nanoTime() - start;\n",
    "\n",
    "System.out.println(\"Generated \" + largeRecords.size() + \" records from cartesian explosion\");\n",
    "System.out.println(\"Expected: 10 items x 5 promos x 3 regions = 150 records\");\n",
    "System.out.println(\"‚è±Ô∏è  Execution time: \" + (elapsed / 1_000_000.0) + \" ms\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"Batch Processing Pattern\");\n",
    "\n",
    "// Simulate batch processing of multiple JSON documents\n",
    "List<String> jsonBatch = List.of(\n",
    "    \"{\\\"id\\\": 1, \\\"items\\\": [{\\\"sku\\\": \\\"A\\\"}]}\",\n",
    "    \"{\\\"id\\\": 2, \\\"items\\\": [{\\\"sku\\\": \\\"B\\\"}, {\\\"sku\\\": \\\"C\\\"}]}\",\n",
    "    \"{\\\"id\\\": 3, \\\"items\\\": [{\\\"sku\\\": \\\"D\\\"}]}\"\n",
    ");\n",
    "\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "List<Map<String, Object>> allRecords = new ArrayList<>();\n",
    "\n",
    "long batchStart = System.nanoTime();\n",
    "for (String json : jsonBatch) {\n",
    "    JsonObject obj = JsonParser.parseString(json).getAsJsonObject();\n",
    "    List<Map<String, Object>> records = flattener.flattenRecords(obj, List.of(\"items\"));\n",
    "    allRecords.addAll(records);\n",
    "}\n",
    "long batchElapsed = System.nanoTime() - batchStart;\n",
    "\n",
    "System.out.println(\"Processed \" + jsonBatch.size() + \" documents\");\n",
    "System.out.println(\"Total flattened records: \" + allRecords.size());\n",
    "System.out.println(\"‚è±Ô∏è  Batch execution time: \" + (batchElapsed / 1_000_000.0) + \" ms\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"milestone-10\"></a>\n",
    "\n",
    "# Milestone 10: End-to-End Workflows\n",
    "\n",
    "## Learning Objectives\n",
    "- Build a complete JSON ‚Üí CSV pipeline\n",
    "- Validate round-trip data integrity\n",
    "- Prepare data for database ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.printSection(\"End-to-End Pipeline\");\n",
    "\n",
    "// Step 1: Source JSON\n",
    "String sourceJson = \"\"\"\n",
    "    {\n",
    "        \"transaction_id\": \"TXN-2024-001\",\n",
    "        \"timestamp\": \"2024-01-15T14:30:00Z\",\n",
    "        \"merchant\": {\n",
    "            \"id\": \"M001\",\n",
    "            \"name\": \"TechStore\",\n",
    "            \"category\": \"electronics\"\n",
    "        },\n",
    "        \"customer\": {\n",
    "            \"id\": \"C001\",\n",
    "            \"email\": \"user@example.com\",\n",
    "            \"tier\": \"premium\"\n",
    "        },\n",
    "        \"items\": [\n",
    "            {\"sku\": \"PHONE-001\", \"name\": \"Smartphone\", \"qty\": 1, \"price\": 999.00},\n",
    "            {\"sku\": \"CASE-002\", \"name\": \"Phone Case\", \"qty\": 2, \"price\": 29.99}\n",
    "        ],\n",
    "        \"payment\": {\n",
    "            \"method\": \"credit_card\",\n",
    "            \"status\": \"completed\",\n",
    "            \"total\": 1058.98\n",
    "        }\n",
    "    }\n",
    "    \"\"\";\n",
    "\n",
    "System.out.println(\"Step 1: Source JSON loaded\");\n",
    "System.out.println(Utils.formatJson(sourceJson));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Step 2: Flatten with array explosion\n",
    "JsonFlattener flattener = new JsonFlattener();\n",
    "JsonObject sourceObj = JsonParser.parseString(sourceJson).getAsJsonObject();\n",
    "List<Map<String, Object>> flatRecords = flattener.flattenRecords(sourceObj, List.of(\"items\"));\n",
    "\n",
    "System.out.println(\"\\nStep 2: Flattened to \" + flatRecords.size() + \" records\");\n",
    "for (int i = 0; i < flatRecords.size(); i++) {\n",
    "    System.out.println(\"\\nRecord \" + (i + 1) + \":\");\n",
    "    System.out.println(flattener.toJson(flatRecords.get(i)));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Step 3: Write to CSV\n",
    "Path pipelineCsvPath = outputDir.resolve(\"transaction_flat.csv\");\n",
    "CsvUtils.writeCsv(flatRecords, pipelineCsvPath);\n",
    "\n",
    "System.out.println(\"\\nStep 3: Written to CSV\");\n",
    "System.out.println(\"File: \" + pipelineCsvPath.toAbsolutePath());\n",
    "System.out.println(\"\\nCSV Preview:\");\n",
    "String csvContent = Files.readString(pipelineCsvPath);\n",
    "System.out.println(csvContent);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Step 4: Round-trip validation\n",
    "List<Map<String, String>> roundTripRecords = CsvUtils.readCsv(pipelineCsvPath);\n",
    "\n",
    "System.out.println(\"\\nStep 4: Round-trip validation\");\n",
    "System.out.println(\"Original record count: \" + flatRecords.size());\n",
    "System.out.println(\"Round-trip record count: \" + roundTripRecords.size());\n",
    "System.out.println(\"‚úì Record counts match: \" + (flatRecords.size() == roundTripRecords.size()));\n",
    "\n",
    "// Verify key fields\n",
    "System.out.println(\"\\nKey field verification:\");\n",
    "for (int i = 0; i < roundTripRecords.size(); i++) {\n",
    "    Map<String, String> record = roundTripRecords.get(i);\n",
    "    System.out.println(\"Record \" + (i + 1) + \": \" + \n",
    "        \"transaction_id=\" + record.get(\"transaction_id\") + \", \" +\n",
    "        \"items.sku=\" + record.get(\"items.sku\") + \", \" +\n",
    "        \"items.name=\" + record.get(\"items.name\"));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Step 5: Generate Snowflake schema\n",
    "String snowflakeSchema = SnowflakeUtils.generateCreateTable(flatRecords, \"TRANSACTIONS_FLAT\", \"ANALYTICS\");\n",
    "\n",
    "System.out.println(\"\\nStep 5: Snowflake schema generated\");\n",
    "System.out.println(snowflakeSchema);\n",
    "\n",
    "System.out.println(\"\\n‚úÖ End-to-end pipeline complete!\");\n",
    "System.out.println(\"Data is ready for:\");\n",
    "System.out.println(\"  - MongoDB ingestion (use MongoUtils.ingestToMongo())\");\n",
    "System.out.println(\"  - Snowflake ingestion (use COPY INTO with the generated schema)\");\n",
    "System.out.println(\"  - Analytics (CSV file ready for import)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting & Tips\n",
    "\n",
    "If a cell fails, try these first:\n",
    "- **Imports fail**: Ensure IJava kernel is properly installed and restart the kernel\n",
    "- **Maven dependencies**: Run the dependency cell first and wait for downloads\n",
    "- **MongoDB errors**: Confirm a local MongoDB is running and `MONGO_URI` points to it\n",
    "- **Snowflake errors**: Verify environment variables (`SNOWFLAKE_*`) and add JDBC driver\n",
    "- **Memory issues**: For large datasets, increase JVM heap size\n",
    "\n",
    "Tip: Restart the kernel and re-run all cells if the environment feels inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Puzzle for Data Scientists\n",
    "\n",
    "You receive 1,000 JSON records with **three array fields**: `items` (avg 4), `promos` (avg 2), and `regions` (avg 3). You flatten by exploding all three paths to create a cartesian product.\n",
    "\n",
    "**Riddle:**\n",
    "- How many records do you expect on average after explosion?\n",
    "- If one region is missing (empty list) in 10% of records, how does that change the expected total?\n",
    "\n",
    "Write your answer and then validate by simulating a small sample in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Random;\n",
    "\n",
    "Random random = new Random(42);\n",
    "\n",
    "int numRecords = 1000;\n",
    "double avgItems = 4.0;\n",
    "double avgPromos = 2.0;\n",
    "double avgRegions = 3.0;\n",
    "double missingRegionRate = 0.10;\n",
    "\n",
    "// Monte Carlo simulation\n",
    "long simulatedTotal = 0;\n",
    "for (int i = 0; i < numRecords; i++) {\n",
    "    // Exponential distribution (approximation)\n",
    "    int items = Math.max(1, (int) (-avgItems * Math.log(random.nextDouble())));\n",
    "    int promos = Math.max(1, (int) (-avgPromos * Math.log(random.nextDouble())));\n",
    "    \n",
    "    int regions;\n",
    "    if (random.nextDouble() < missingRegionRate) {\n",
    "        regions = 0;\n",
    "    } else {\n",
    "        regions = Math.max(1, (int) (-avgRegions * Math.log(random.nextDouble())));\n",
    "    }\n",
    "    \n",
    "    simulatedTotal += items * promos * Math.max(1, regions);\n",
    "}\n",
    "\n",
    "System.out.println(\"Simulated total records: \" + simulatedTotal);\n",
    "System.out.println(\"Average per input record: \" + (simulatedTotal / (double) numRecords));\n",
    "\n",
    "double expectedNoMissing = avgItems * avgPromos * avgRegions;\n",
    "double expectedWithMissing = avgItems * avgPromos * ((1 - missingRegionRate) * avgRegions + missingRegionRate * 1);\n",
    "\n",
    "System.out.println(\"\\nExpected (no missing regions): \" + expectedNoMissing);\n",
    "System.out.println(\"Expected (10% missing regions): \" + expectedWithMissing);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This Java notebook demonstrated:\n",
    "\n",
    "1. **Core JSON Flattening** - Converting nested structures to flat maps\n",
    "2. **Array Policies** - INDEX vs JOIN approaches\n",
    "3. **Cartesian Products** - Exploding multiple array paths\n",
    "4. **CSV Operations** - Read/write with OpenCSV\n",
    "5. **MongoDB Integration** - Document ingestion and querying\n",
    "6. **Snowflake Schema** - DDL generation for data warehousing\n",
    "7. **Performance** - Timing measurements for batch operations\n",
    "8. **End-to-End Pipelines** - Complete JSON ‚Üí CSV ‚Üí Database workflows\n",
    "\n",
    "### Key Java Libraries Used:\n",
    "- **Gson** - JSON parsing and serialization\n",
    "- **OpenCSV** - CSV read/write operations\n",
    "- **MongoDB Java Driver** - Database integration\n",
    "- **Apache Commons Lang** - String utilities\n",
    "\n",
    "### Next Steps:\n",
    "- Add Spark integration for large-scale processing\n",
    "- Implement streaming JSON processing\n",
    "- Add schema evolution handling\n",
    "- Build production-grade error handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
